---
# =============================================================================
# Cline CLI - Docker Compose
# =============================================================================
# Usage:
#   1. Copy .env.example to .env and fill in your credentials
#   2. docker compose run --rm cline                   # interactive session
#   3. docker compose run --rm cline -y "fix tests"    # headless task
# =============================================================================

services:
  cline:
    image: ${DOCKER_IMAGE:-your-org/cline}:${IMAGE_TAG:-latest}
    # To build locally instead of pulling:
    # build:
    #   context: .
    #   args:
    #     CLINE_VERSION: "2.5.0"

    environment:
      # ── AI Provider (OpenAI-compatible) ──────────────────────────────────────
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      # Optional: custom endpoint (Azure OpenAI, Ollama, vLLM, etc.)
      # - OPENAI_BASE_URL=${OPENAI_BASE_URL:-}
      # Optional: model override (default: gpt-4o)
      # - CLINE_MODEL=${CLINE_MODEL:-}

      # ── Azure DevOps (optional) ──────────────────────────────────────────────
      # Set ADO_PAT to enable az devops CLI and azure-devops Python SDK auth.
      # ADO_ORG is required when ADO_PAT is set; ADO_PROJECT is optional.
      # - ADO_ORG=${ADO_ORG:-}           # org name, e.g. contoso
      # - ADO_PAT=${ADO_PAT:-}           # Personal Access Token
      # - ADO_PROJECT=${ADO_PROJECT:-}   # default project name

      # ── Corporate Proxy (optional) ───────────────────────────────────────────
      # - HTTPS_PROXY=${HTTPS_PROXY:-}
      # - HTTP_PROXY=${HTTP_PROXY:-}
      # - NO_PROXY=${NO_PROXY:-}

    volumes:
      # Mount your project as the working directory
      - .:/workspace

      # Persist Cline config & settings across sessions
      - cline-data:/home/node/.cline/data

    working_dir: /workspace

    # Required for Cline's interactive TUI
    stdin_open: true
    tty: true

volumes:
  cline-data:
    driver: local
