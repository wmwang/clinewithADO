# =============================================================================
# Cline — Environment Variables
# =============================================================================
# Copy this file to .env and fill in your values.
# Never commit .env to version control.
# =============================================================================

# ── Docker image settings ────────────────────────────────────────────────────
DOCKER_IMAGE=your-org/cline
IMAGE_TAG=latest

# ── AI Provider (OpenAI-compatible) ─────────────────────────────────────────

# Required: API key
OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Optional: custom endpoint
# Standard OpenAI:  leave unset
# Azure OpenAI:     OPENAI_BASE_URL=https://<resource>.openai.azure.com/openai/deployments/<deployment>
# Ollama (local):   OPENAI_BASE_URL=http://host.docker.internal:11434/v1
# LM Studio:        OPENAI_BASE_URL=http://host.docker.internal:1234/v1
# OPENAI_BASE_URL=https://your-endpoint/v1

# Optional: model override (default: gpt-4o)
# CLINE_MODEL=gpt-4o

# ── Corporate Proxy (optional) ───────────────────────────────────────────────
# Required if your network uses a proxy to reach AI providers.
# HTTPS_PROXY=http://proxy.corp.com:8080
# HTTP_PROXY=http://proxy.corp.com:8080
# NO_PROXY=localhost,127.0.0.1,.corp.internal
